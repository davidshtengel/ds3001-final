{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0157b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d29c6",
   "metadata": {},
   "source": [
    "### **Dataset Examination & Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df255c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker, TickerType, Company, Traded, Transaction, Trade_Size_USD, Status, Subholding, Description, Name, Filed, Party, District, Chamber, Comments, Quiver_Upload_Time, excess_return, State, last_modified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Traded</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Trade_Size_USD</th>\n",
       "      <th>Name</th>\n",
       "      <th>Filed</th>\n",
       "      <th>Party</th>\n",
       "      <th>District</th>\n",
       "      <th>Chamber</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGL</td>\n",
       "      <td>Monday, March 11, 2024</td>\n",
       "      <td>Sale</td>\n",
       "      <td>$15,001 - $50,000</td>\n",
       "      <td>Mark Dr Green</td>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>R</td>\n",
       "      <td>TN07</td>\n",
       "      <td>House</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCX</td>\n",
       "      <td>Thursday, February 29, 2024</td>\n",
       "      <td>Sale</td>\n",
       "      <td>$1,001 - $15,000</td>\n",
       "      <td>Josh Gottheimer</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>D</td>\n",
       "      <td>NJ05</td>\n",
       "      <td>House</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V</td>\n",
       "      <td>Thursday, February 29, 2024</td>\n",
       "      <td>Purchase</td>\n",
       "      <td>$1,001 - $15,000</td>\n",
       "      <td>Pete Sessions</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>R</td>\n",
       "      <td>TX17</td>\n",
       "      <td>House</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPLE INC. (XNAS:AAPL)</td>\n",
       "      <td>Thursday, February 29, 2024</td>\n",
       "      <td>Purchase</td>\n",
       "      <td>$360.00</td>\n",
       "      <td>Pete Sessions</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>R</td>\n",
       "      <td>TX17</td>\n",
       "      <td>House</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Thursday, February 29, 2024</td>\n",
       "      <td>Sale</td>\n",
       "      <td>$100,001 - $250,000</td>\n",
       "      <td>Suzan K. Delbene</td>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>D</td>\n",
       "      <td>WA01</td>\n",
       "      <td>House</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Ticker                       Traded Transaction  \\\n",
       "0                     NGL       Monday, March 11, 2024        Sale   \n",
       "1                     FCX  Thursday, February 29, 2024        Sale   \n",
       "2                       V  Thursday, February 29, 2024    Purchase   \n",
       "3  APPLE INC. (XNAS:AAPL)  Thursday, February 29, 2024    Purchase   \n",
       "4                    MSFT  Thursday, February 29, 2024        Sale   \n",
       "\n",
       "        Trade_Size_USD              Name       Filed Party District Chamber  \\\n",
       "0    $15,001 - $50,000     Mark Dr Green  2024-03-13     R     TN07   House   \n",
       "1     $1,001 - $15,000   Josh Gottheimer  2024-03-07     D     NJ05   House   \n",
       "2     $1,001 - $15,000     Pete Sessions  2024-03-07     R     TX17   House   \n",
       "3              $360.00     Pete Sessions  2024-02-29     R     TX17   House   \n",
       "4  $100,001 - $250,000  Suzan K. Delbene  2024-03-08     D     WA01   House   \n",
       "\n",
       "        State  \n",
       "0   Tennessee  \n",
       "1  New Jersey  \n",
       "2       Texas  \n",
       "3       Texas  \n",
       "4  Washington  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATASET\n",
    "raw_dataset = pd.read_csv('congressional-trading-dataset/congress-trading-all.csv')\n",
    "print(*raw_dataset.columns.to_list(), sep=', ')\n",
    "raw_dataset = raw_dataset.drop(columns=['TickerType', 'Company', 'Subholding', 'Comments', 'Quiver_Upload_Time', 'Description', 'Status', 'Comments', 'last_modified', 'excess_return'])\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc0fe5",
   "metadata": {},
   "source": [
    "### **Initial Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedfdd2",
   "metadata": {},
   "source": [
    "#### `Ticker` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d056e1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 3966 unique tickers, there are 123 \"weird\" tickers (length > 5 characters)\n",
      "07/01/28 | 07/01/36 | 0QZI.IL | 12/01/37 | 13.WEEK MATURE | 13.WEEK, MATURE | 3.MONTH, MATURE | 3305779 | 36966R5P7 | 3V64.TI | 4.WEEK MATURE | 4.WEEK, MATURE | 40055AY43 | 40056FN84 | 4491235 | 4824778 | 506120KP8 | 5522714 | 6.MONTH | 6.MONTH, MATURE | 605699PU5 | 6320058 | 6897143 | 784532JF1 | 8.WEEK, MATURE | 912796QV4 | 912796QX0 | 912796SH3 | 912796U31 | 912796U49 | 912796WX3 | 912796X87 | 912796XQ7 | 912796YH6 | 912796YJ2 | 912796ZP7 | 912797LL9 | 91282CDR9 | 91282CEG2 | 91282CFG1 | 91282CFN6 | 914476PV2 | AAIC$B | AEX.MU | ALLY.A | APPLE INC. (XNAS:AAPL) | B0T4J94 | B13WZ26 | B1W8P14 | B1WSP14 | B5NC0D0 | B923935 | BAC.PL | BACWSA | BANC$E | BELGIUM | BLM7FC2 | BN7Q3G8 | BOT4J94 | BUNT.RP | CARDONA | CLNS$A | CMLPSX | COF.PP | CORPORAT | CTECBX | CTFS PARTN | CWEN.A | D/B/A ELLIOTT | DUE 04/01/27 | DUE 07/01/25 | DUE 07/01/27 | DUE 08/01/25 | DUE 10/01/203 | DUE 10/01/37 | DUE 12/01/27 | DUE 12/01/29 | DUE 7/01/20 | DUK PA | ETWO.W | FL4.SG | FUND 2 | FUND 2 LTH | GLAS FUNDS | GLAS FUNDS, LP | HAMILTO | HOSPIC | IBM.MX | INSW.V | INVESTMEN | LM09.SG | MATURE | MATURIT | MONTGOMERY, AL .2, SCHAUMBERG, IL .1 | MSTY.PA | NASDAQ | NASDAQ:WLTW | NEE.PC | NEE.PRI | NGLS$A | NORTHWESTER | NYLD.A | NYSE: COV | ONE SHARE FOR ONE SHARE | OSRN DE | PART INTEREST | PCPL.U | QCGLIX | QCGRIX | QCSTIX | QREARX | RDSA.AS | SBUX.SW | SCHW$D | SPY160219P00180000 | STATE OF | SYY.SG | TREASURY INFLATIO | U 3%25CD | USB.PN | XER.BE | XLS.WI | ZNGA.SW\n"
     ]
    }
   ],
   "source": [
    "# FIND/PRINT \"WEIRD\" TICKERS TO CATEGORIZE/REMOVE, IF APP.\n",
    "ticker_list = raw_dataset['Ticker'].unique().tolist()\n",
    "weird_tickers = list(filter(lambda t: len(t)>5, ticker_list))\n",
    "weird_tickers.sort()\n",
    "print(f'Of {len(ticker_list)} unique tickers, there are {len(weird_tickers)} \"weird\" tickers (length > 5 characters)')\n",
    "print(*weird_tickers, sep=\" | \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f77abd",
   "metadata": {},
   "source": [
    "**Notable Types of \"Weird\" Tickers**\n",
    "- **Preferred Stock**: Tickers w/ `$`, `.P`, `.PC`, `.PN`, `.PP`, etc.\n",
    "  - From [Investopedia](https://www.investopedia.com/articles/01/070401.asp), \"an extra letter might be tacked on at the end to identify the type of share or to identify preferred stock.\"\n",
    "- **CUSIP**: `^[0-9A-Z]{9}$`, including `91282CDR9`, `506120KP8`, etc.\n",
    "  - From [Investopedia](https://www.investopedia.com/terms/c/cusipnumber.asp), these are called a  *CUSIP number*, \"a series of letters and numbers used to identify certain securities and facilitate trading and settlement,\" and are used in the United States and Canada. \n",
    "- **Funds**: Mutual Funds all have tickers that end with an `X`\n",
    "- **Option Contracts**: `SPY160219P00180000`, etc.\n",
    "  - OCC Option symbol (consists of root symbol, exp. date, option type (put/call), strike price)\n",
    "- **Foreign Stock**: Tickers like `IBM.MX`, `RDSA.AS`, `CWEN.A`, `SYY.SG`, etc.\n",
    "\n",
    "Can't make confident judgement on other tickers, will likely purge from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8809e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE/REMOVE ILL-FORMATTED OR UNIDENTIFIABLE TICKER\n",
    "def inspect_ticker(ticker: str):\n",
    "    if len(ticker) <= 5:\n",
    "        return False\n",
    "    elif re.match(r\"^[0-9A-Z]{9}$\", ticker):\n",
    "        return \"Security\"\n",
    "    elif re.match(r\"^[A-Z]{1,5}\\$[A-Z]{1,3}$\", ticker):\n",
    "        return ticker\n",
    "    elif re.match(r\"^[A-Z]{1,5}\\.[A-Z]{1,3}$\", ticker):\n",
    "        return \"Foreign_Stock\"\n",
    "    else:\n",
    "        inside_string = re.search(r\"([A-Z]{2,6}):\\s*([A-Z]{1,5})\", ticker)\n",
    "        if inside_string:\n",
    "            return inside_string.group(2)\n",
    "        else:\n",
    "            return \"REMOVE\"\n",
    "\n",
    "def drop_bad_tickers(dataset: pd.DataFrame):\n",
    "    df = dataset.copy()\n",
    "    drop_indices = []\n",
    "    for index, row in df.iterrows():\n",
    "        new_ticker = inspect_ticker(row['Ticker'])\n",
    "        if new_ticker is False:\n",
    "            continue\n",
    "        elif new_ticker == \"REMOVE\":\n",
    "            print(f\"Dropping {row['Ticker']}... (index {index})\")\n",
    "            drop_indices.append(index)\n",
    "        else:\n",
    "            df.loc[index, 'Ticker'] = new_ticker\n",
    "    df = df.drop(index=drop_indices)\n",
    "    return drop_indices, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38550443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping GLAS FUNDS, LP... (index 90)\n",
      "Dropping HAMILTO... (index 93)\n",
      "Dropping GLAS FUNDS, LP... (index 137)\n",
      "Dropping 4.WEEK, MATURE... (index 154)\n",
      "Dropping 3.MONTH, MATURE... (index 328)\n",
      "Dropping 6.MONTH, MATURE... (index 486)\n",
      "Dropping GLAS FUNDS... (index 526)\n",
      "Dropping GLAS FUNDS, LP... (index 645)\n",
      "Dropping GLAS FUNDS, LP... (index 1147)\n",
      "Dropping 13.WEEK, MATURE... (index 1148)\n",
      "Dropping GLAS FUNDS, LP... (index 1180)\n",
      "Dropping 4.WEEK, MATURE... (index 1718)\n",
      "Dropping 3.MONTH, MATURE... (index 1862)\n",
      "Dropping DUE 10/01/203... (index 1879)\n",
      "Dropping 8.WEEK, MATURE... (index 2558)\n",
      "Dropping 4.WEEK, MATURE... (index 2561)\n",
      "Dropping GLAS FUNDS... (index 2590)\n",
      "Dropping MATURE... (index 2669)\n",
      "Dropping BELGIUM... (index 2783)\n",
      "Dropping STATE OF... (index 2969)\n",
      "Dropping 4.WEEK, MATURE... (index 2994)\n",
      "Dropping STATE OF... (index 3195)\n",
      "Dropping MATURIT... (index 4105)\n",
      "Dropping MATURIT... (index 4214)\n",
      "Dropping 13.WEEK, MATURE... (index 4273)\n",
      "Dropping 4.WEEK MATURE... (index 4518)\n",
      "Dropping 13.WEEK MATURE... (index 4559)\n",
      "Dropping TREASURY INFLATIO... (index 4969)\n",
      "Dropping 6.MONTH... (index 4975)\n",
      "Dropping U 3%25CD... (index 6578)\n",
      "Dropping FUND 2... (index 8009)\n",
      "Dropping FUND 2 LTH... (index 8025)\n",
      "Dropping CORPORAT... (index 8326)\n",
      "Dropping CARDONA... (index 8748)\n",
      "Dropping BELGIUM... (index 9484)\n",
      "Dropping MONTGOMERY, AL .2, SCHAUMBERG, IL .1... (index 9666)\n",
      "Dropping FL4.SG... (index 10430)\n",
      "Dropping PART INTEREST... (index 10763)\n",
      "Dropping NASDAQ... (index 11088)\n",
      "Dropping D/B/A ELLIOTT... (index 11401)\n",
      "Dropping CTECBX... (index 16600)\n",
      "Dropping 12/01/37... (index 21229)\n",
      "Dropping 3V64.TI... (index 21563)\n",
      "Dropping 3V64.TI... (index 21567)\n",
      "Dropping 0QZI.IL... (index 21572)\n",
      "Dropping 0QZI.IL... (index 21591)\n",
      "Dropping DUE 7/01/20... (index 21990)\n",
      "Dropping DUE 10/01/37... (index 22374)\n",
      "Dropping DUE 08/01/25... (index 22376)\n",
      "Dropping 07/01/36... (index 23624)\n",
      "Dropping 07/01/28... (index 23650)\n",
      "Dropping DUK PA... (index 24491)\n",
      "Dropping LM09.SG... (index 26545)\n",
      "Dropping LM09.SG... (index 26591)\n",
      "Dropping LM09.SG... (index 26934)\n",
      "Dropping LM09.SG... (index 26957)\n",
      "Dropping ONE SHARE FOR ONE SHARE... (index 27715)\n",
      "Dropping ONE SHARE FOR ONE SHARE... (index 27850)\n",
      "Dropping NORTHWESTER... (index 28956)\n",
      "Dropping CMLPSX... (index 31403)\n",
      "Dropping BACWSA... (index 35590)\n",
      "Dropping 3305779... (index 37029)\n",
      "Dropping 4824778... (index 37037)\n",
      "Dropping 3305779... (index 37038)\n",
      "Dropping 6897143... (index 37041)\n",
      "Dropping B13WZ26... (index 37049)\n",
      "Dropping BLM7FC2... (index 37052)\n",
      "Dropping 5522714... (index 37056)\n",
      "Dropping 4491235... (index 37057)\n",
      "Dropping B1W8P14... (index 37063)\n",
      "Dropping 4491235... (index 37586)\n",
      "Dropping DUE 12/01/29... (index 37911)\n",
      "Dropping DUE 07/01/25... (index 37912)\n",
      "Dropping B923935... (index 38675)\n",
      "Dropping BOT4J94... (index 38676)\n",
      "Dropping SPY160219P00180000... (index 38684)\n",
      "Dropping SPY160219P00180000... (index 38715)\n",
      "Dropping SPY160219P00180000... (index 38726)\n",
      "Dropping QCGLIX... (index 39101)\n",
      "Dropping QCSTIX... (index 39103)\n",
      "Dropping QREARX... (index 39111)\n",
      "Dropping QCGLIX... (index 39113)\n",
      "Dropping QCGRIX... (index 39119)\n",
      "Dropping QREARX... (index 39120)\n",
      "Dropping QCSTIX... (index 39125)\n",
      "Dropping B1WSP14... (index 39289)\n",
      "Dropping DUE 12/01/27... (index 39856)\n",
      "Dropping DUE 04/01/27... (index 40078)\n",
      "Dropping DUE 07/01/27... (index 40214)\n",
      "Dropping CTFS PARTN... (index 40967)\n",
      "Dropping B0T4J94... (index 41649)\n",
      "Dropping BN7Q3G8... (index 41756)\n",
      "Dropping HOSPIC... (index 42994)\n",
      "Dropping B13WZ26... (index 43360)\n",
      "Dropping B13WZ26... (index 43364)\n",
      "Dropping B13WZ26... (index 43374)\n",
      "Dropping 6320058... (index 43550)\n",
      "Dropping BN7Q3G8... (index 43553)\n",
      "Dropping OSRN DE... (index 43827)\n",
      "Dropping 6320058... (index 44769)\n",
      "Dropping B5NC0D0... (index 44774)\n",
      "Dropping 4824778... (index 44775)\n",
      "Dropping 6897143... (index 44776)\n",
      "Dropping 4491235... (index 44777)\n",
      "Dropping B0T4J94... (index 44778)\n",
      "Dropping B13WZ26... (index 44779)\n",
      "Dropping 5522714... (index 44780)\n",
      "Dropping PART INTEREST... (index 46366)\n",
      "Of the 123 'weird' tickers originally flagged, regex matching narrowed the 'weird' to 108 'bad' tickers, which were dropped!\n"
     ]
    }
   ],
   "source": [
    "# CLEAN DATASET['TICKERS']\n",
    "dropped, updated_dataset = drop_bad_tickers(raw_dataset)\n",
    "print(f\"Of the {len(weird_tickers)} 'weird' tickers originally flagged, regex matching narrowed the 'weird' to {len(dropped)} 'bad' tickers, which were dropped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fae46b",
   "metadata": {},
   "source": [
    "#### `Traded` Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba7a55",
   "metadata": {},
   "source": [
    "**Other attributes** (`Filed`, etc.) with date values adhere to a `YYYY-MM-DD` format, so it follow that this column's values should be converted to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c8a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT LONG DATE STRING INTO MORE COMPACT YYYY-MM-DD FORMAT\n",
    "def shorten_date_string(date: str):\n",
    "    dt = datetime.strptime(date, '%A, %B %d, %Y')\n",
    "    return dt.strftime('%Y-%m-%d')\n",
    "\n",
    "for index, row in updated_dataset.iterrows():\n",
    "    updated_dataset.loc[index, 'Traded'] = shorten_date_string(row['Traded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcae337",
   "metadata": {},
   "source": [
    "#### `Trade_Size_USD` Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWRITE VALUE INTO APPLICABLE BUCKETS, DISCARD THE REST\n",
    "trade_size_buckets = ['$1-$1,000',\n",
    "                      '$1,001 - $15,000',\n",
    "                      '$15,001 - $50,000',\n",
    "                      '$50,001 - $100,000',\n",
    "                      '$100,001 - $250,000',\n",
    "                      '$250,001 - $500,000',\n",
    "                      '$500,001 - $1,000,000',\n",
    "                      '$1,000,001 - $5,000,000',\n",
    "                      '$5,000,001 - $25,000,000',\n",
    "                      '$25,000,001 - $50,000,000']\n",
    "\n",
    "def parse_money(s):\n",
    "    s = s.strip().replace('$', '').replace(',', '')\n",
    "    s = re.sub(r'[^\\d\\.]', '', s)  # Remove trailing . or ,\n",
    "    return float(s) if s else None\n",
    "\n",
    "def parse_range(trade_size):\n",
    "    m = re.match(r'^\\s*\\$(.+?)\\s*-\\s*\\$(.+?)[\\.,]?\\s*$', trade_size\n",
    "    )\n",
    "    if m:\n",
    "        low, high = parse_money(m.group(1)), parse_money(m.group(2))\n",
    "        if low is not None and high is not None:\n",
    "            return min(low, high), max(low, high)\n",
    "    m = re.match(r'^\\s*\\$([\\d,]+(?:\\.\\d{2})?)\\s*$', trade_size)\n",
    "    if m:\n",
    "        v = parse_money(m.group(1))\n",
    "        if v is not None:\n",
    "            return v, v\n",
    "    return None\n",
    "\n",
    "def parse_bucket(bucket):\n",
    "    m = re.match(r'^\\$(.+?)[ ]*-[ ]*\\$(.+)$', bucket.replace(',', ''))\n",
    "    if m:\n",
    "        low = parse_money(m.group(1))\n",
    "        high = parse_money(m.group(2))\n",
    "        return bucket, low, high\n",
    "    return None\n",
    "\n",
    "bucket_ranges = [parse_bucket(b) for b in trade_size_buckets]\n",
    "\n",
    "def inspect_trade_size(trade_size: str):\n",
    "    # Already in canonical bucket\n",
    "    if trade_size in trade_size_buckets:\n",
    "        return False\n",
    "    \n",
    "    r = parse_range(trade_size)\n",
    "    if not r:\n",
    "        return \"REMOVE\"\n",
    "    trade_min, trade_max = r\n",
    "\n",
    "    matching_buckets = []\n",
    "    for label, bucket_min, bucket_max in bucket_ranges:\n",
    "        if trade_min >= bucket_min and trade_max <= bucket_max:\n",
    "            matching_buckets.append(label)\n",
    "    \n",
    "    if len(matching_buckets) == 1:\n",
    "        return matching_buckets[0]\n",
    "    else:\n",
    "        return \"REMOVE\"\n",
    "    \n",
    "bucket_ranges = [parse_bucket(b) for b in trade_size_buckets]\n",
    "def drop_bad_trades(dataset: pd.DataFrame):\n",
    "    df = dataset.copy()\n",
    "    drop_indices = []\n",
    "    for index, row in df.iterrows():\n",
    "        new_trade_size = inspect_trade_size(row['Trade_Size_USD'])\n",
    "        if new_trade_size is False:\n",
    "            continue\n",
    "        elif new_trade_size == \"REMOVE\":\n",
    "            print(f\"Dropping {row['Trade_Size_USD']}... (index {index})\")\n",
    "            drop_indices.append(index)\n",
    "        else:\n",
    "            df.loc[index, 'Trade_Size_USD'] = new_trade_size\n",
    "    df = df.drop(index=drop_indices)\n",
    "    return drop_indices, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54625ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping $1,000.22... (index 15739)\n",
      "Dropping $.01 - $0.00... (index 15818)\n",
      "Dropping $6.20 - $100,001... (index 39169)\n",
      "Dropping $6.20 - $15,001... (index 39174)\n",
      "Dropping $6.20 - $15,001... (index 39211)\n",
      "Dropping $1.26 - $50,001... (index 41749)\n",
      "Dropping $1.26 - $250,001... (index 42000)\n",
      "Dropping $1.26 - $1,001... (index 42011)\n",
      "Dropping $250,001-$500,000 - $100,001... (index 42456)\n",
      "Dropping $50,001-$100,000. - $15,001... (index 42637)\n"
     ]
    }
   ],
   "source": [
    "# CLEAN TRADE SIZE ATTRIBUTE\n",
    "drop_indices, cleaned_df = drop_bad_trades(updated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2515d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE \"CLEANED\" DATASET\n",
    "cleaned_df.to_csv('prepared_congress_trading_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc87e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-3001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
